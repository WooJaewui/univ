# 텍스트 빅데이터.

-----------------------------------------------------------------------------------

> ## 텍스트 처리와 자연어 처리.

### 텍스트 text.
- 숫자와 더불어 가장 대표적인 정보의 저장 단위.
- 소셜네트워크 서비스의 성장 -> 중요성이 점차 커짐.
- 기본적으로는 명목 데이터 nominal data.
- 비명목 데이터로 활용하기 위해서는 텍스트 프로세싱과 같은 작업이 선행되어야 함.

### 텍스트 프로세싱 Text Processing.
- 텍스트에서 의미 있는 정보를 찾아내는 과정.
- 자연어처리(Natural Language Processing)와는 차이가 있음.
- 자연어처리는 텍스트는 물론, 음성기반의 대화, 이미지, 사인 등 많은 것들을 대상으로 함.
- 빅데이터 분석에서 텍스트 처리는 대부분 자연처리에 초점을 맞추고 진행.
  <br>(자연어처리와 텍스트 분석을 나누는 것이 의미가 없어짐)

-----------------------------------------------------------------------------------

> ## 자연어처리 기술의 활용.

### 자연어 Natural Language.
- 우리가 일상적으로 쓰는 언어.
- 소셜데이터를 활용한 빅데이터 분석의 대상은 자연어인 경우가 대부분.
  - 텍스트 요약과 분류.
  - 감성 분석.
  - 의미연결망 분석.
  - 기계번역.
  - 질의응답과 챗봇.
  - 음성 인식.

### 텍스트 분류 Text Classification.
- 텍스트가 어떤 범주에 속하는지 판단하는 작업.
- 일반적으로 텍스트로부터 특징을 추출하고 이를 바탕으로 학습된 모형을 구축.
  - 이메일의 스팸 분류.
  - 텍스트의 감정 분석.

### 감성 분석 Sentiment Analysis.
- 텍스트에 포함된 의견이나 감정 등을 분석.
- 영화평 분석, 고객의 의견 분석, 유권자 메시지 분석 등.

### 의미연결망 분석 Sentiment Network Analysis.
- 단어의 네트워크를 구성하여 단어 간의 관계성을 파악.
- 특정 키워드가 내포하는 의미를 확장하여 살펴보는데 유용.

### 질의응답 Question Answering.
- 주어진 질의에 대한 답을 찾아 제시하는 연구.
- 기계독해 이해력 테스트를 위한 데이터셋 SQuAD가 공개되며 관련 연구 활발히 진행.
- SQuAD Stanford Question Answering Dataset.

### 챗봇 Chatbot.
- 사용자의 발화에서 숨은 의도를 찾아내고 자연스러운 인간의 언어로 답변해주는 서비스.
- 챗봇의 주요 기술은 텍스트 분류, 질의응답 등 앞서 소개한 기술들이 활용 됨.

-----------------------------------------------------------------------------------

> ## 텍스트 전처리.

### 텍스트 전처리 Text Preprocessing.
- 텍스트 분석의 궁극적 목표는 텍스트가 가진 함의의 이해.
- 그러나 컴퓨터는 텍스트를 바로 연산하여 분석할 수 없음.
- 따라서 분석 전에 토큰화 혹은 정규화 등의 텍스트 전처리 작업이 필요.

### 토큰화 Tokenization.
- 문장을 가장 작은 단위로 나누는 작업.
- 전통적으로는 토큰으로 단어를 사용.
- 단어 토큰화를 하는 가장 쉬운 방법은 띄어쓰기를 중심으로 토큰을 만드는 것.

### 정규화 Normalization.
- 같은 의미지만 표기가 다른 단어들을 통합하는 방법.
- 정규화 과정에서 주의를 기울여야 함. (동음이의어)
- 영어의 관사, 전치사, 우리말의 조사 등은 분석에 필요하지 않은 단어라 삭제하여야 함.

### 어간 추출과 형태소 분석.
- 같은 의미의 단어를 통합하는 과정에서 주로 많이 사용하는 방법은 단어의 원형을 추출하는 것.
- 영어의 경우 어간 추출 혹은 표제어 추출을 통해 원형 추출.
- 한글의 경우 형태소 분석기를 이용하여 단어의 기본형 추출.
- 형태소 분석기는 단어의 기본형을 추출하고 품사를 태깅.

### 원-핫 인코딩 One-Hot Encoding.
- 컴퓨터는 연산과정에서 숫자를 사용하기 때문에 자연어 처리 과정에서 문자를 숫자로 변환.
- 원-핫 인코딩은 출현한 모든 단어 사전 크기의 벡터를 만들고 특정 단어의 위치를 숫자로 표시한 것.

-----------------------------------------------------------------------------------

> ## 단어의 표현방법.

### 단어의 표현방법.
- 컴퓨터는 사람과 같이 문장과 단어를 이해할 수 없기 때문에 숫자로 치환해서 표현하는 방법을 사용.

### 단어가방모형 BoW Bag of Words.
- 단어가방모형은 매우 오래된 텍스트 모형으로 단순한 통계적 언어모형의 하나임.
- 단어의 순서는 고려하지 않고, 각 단어의 출현 빈도만을 계산함.
- 전체에 출현한 단어의 리스트를 만들고 개별단어가 문서에 몇 번 등장하는지를 세는 것.

### 문서-단어 행렬 Document-Term Matrix.
- 단어가방모형을 이용하여 문서에 출현하는 단어들의 빈도를 행렬로 표현한 것.
- 특정 단어가 포함된 문서를 찾거나 특정 단어가 어떤 문서에서 얼마나 중요도를 가지는지 파악하기 쉬움.
- 모든 단어가 숫자로 표현되기 때문에 행렬을 이용한 다양한 연산이 가능.

### TF-IDF Term Frequency Inverse Document Frequency.
- 단어 빈도를 뜻하는 TF는 특정한 단어가 문서 내에서 얼마나 자주 등장하는지를 나타냄.
- 일반적으로 특정 단어의 TF값이 높으면 문서에서 중요한 단어라고 판단.
- 단어가 여러 문서에서 공통적으로 자주 등장한다면 그 단어의 중요도는 상대적으로 낮아짐.
  <br> ( 예: a, the, of, is, ... 등 )
- DF = 해당 단어가 나타난 문서 수 / 전체 문서 수.
- IDF = log(전체 문서 수 / 해당 단어가 나타난 문서 수)
- 검색 엔진에서 많이 사용 된다.

-----------------------------------------------------------------------------------

> ## 언어 모형.

### 언어모형 Language Model.
- 특정 단어나 문장이 있을 때 다음에 나타날 단어나 문장에 대한 확률적 분포를 구함.
- 과거에는 통계적 모형이 주로 이용되었지만 최근에는 인공신경망을 이용한 모형이 주로 사용됨.
- 언어모형을 구축하기 위해서는 텍스트 빅데이터의 학습이 필요한데 N-gram 언어모형이 많이 사용됨.

### N-gram 언어모형.
- 단어의 출현횟수에 기반하여 통계적 모델을 구축함.
- 시퀀스 예측을 위해 이전에 등장한 단어를 모두 예측하지 않고 일부 단어만을 사용.









