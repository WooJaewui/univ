
# SVNM과 커널법.

---------------------------------------------------------------------------------------------------------------

> ## 선형 분류기.

### 과다적합.
- 과다학습을 피하고 일반화 오차를 줄이기 위해서는 학습 시스템의 복잡도를 적절히 조정하는 것이 중요. (선형)

### 선형 분류기 linear classifier.
- 선형 판별함수를 기반으로 분류를 수행하는 학습 시스템.
- 분류 시스템의 복잡도가 가장 낮으며, 분류 성능도 좋지 못함.
- 과다적합의 발생을 피할 수 있음.
- SVM -> 일반화 오차를 최소화할 수 있는 방향으로 학습이 이루어지도록 설계된 선형 분류기.

### 선형 초평면 분류기.
- 최소 학습 오차를 만족하는 여러 가지 선형 결정경계가 존재.
- SVM에서는 여러 선형 결정경계 중 일반화 오차를 최소로 하는 최적의 경계를 찾기 위해 마진의 개념을 도입하여 목적함수를 정의.

---------------------------------------------------------------------------------------------------------------

> ## SVM 분류기.

### 최대 마진 분류기 maximum margin classifier.
- 마진.
  - 학습 데이터들 중에서 결정경계에 가장 가까운 데이터로부터 결정경계까지의 거리.
- 서포트 벡터.
  - 결정경계에 가장 가까운 곳에 위치한 데이터.

### SVM Support Vector Machine.
- 일반화 오차를 작게 -> 클래스 간의 간격을 최대로 -> 마진을 최대로 -> 최대 마진 분류기.

### SVM 학습.
- 학습 데이터.
  - {(x1,y1)} i=1,...N  => yi = +1 if xi ∈ C1<br>
                        => yi = -1 if xi ∈ C2
- 추정해야 할 파라미터 w, w0가 만족해야 하는 조건.
  - yi((W**T)xi + w0) -1 >= 0
- 최소화할 목적함수.
  - J(w) = (||w||**2) / 2
  - w를 최소화시켜야 함. (미분)
- 서포트 벡터에 해당하는 ^ai와 학습 데이터 (xi,yi)만 필요.
  - 분류를 위해 저장할 데이터의 개수와 계산량의 현격한 감소.

### 다중 클래스 분류 문제에의 적용.
- 1대 나머지 방법 one-versus-the-rest.
  - 가장 보편적인 방법 -> k개의 개별적인 SVM 분류기 사용.
  - k번째 SVM -> k번째 클래스와 나머지 k-1개의 클래스를 분류.
    - 클래스 Ck에 해당하는 데이터는 +1이 되도록 학습.
    - 나머지 k-1개의 클래스의 데이터에 대해서는 -1이 되도록 학습.
  - 문제 : 애매모호한 결정 영역, 학습 데이터 집합의 크기가 불균형적.
- 1대1 방법 one-versus-one.
  - 가능한 모든 클래스의 쌍에 대한 서로 다른 k(k-1)/2 개의 SVM과 보팅.
  - 문제 : 애매모호한 결정 영역, 학습/테스트를 위한 높은 계산 비용.

### 슬랙변수를 가진 SVM.
- 선형 분리가 불가능한 데이터 처리를 위해 슬랙변수 도입.
- 슬랙변수 ∫.  
  - 잘못 분류된 데이터로부터 해당 클래스의 결정경계까지의 거리.
  - 슬랙변수의 값이 클수록 더 심한 오분류를 허용.

---------------------------------------------------------------------------------------------------------------

> ## 커널법.

### 비선형 문제로의 확장.
- 고차원 문제로 선형화하면 간단한 선형 분류기를 사용한 분류가 가능.
- 계산량 증가와 같은 부작용 발생.
  - 커널법으로 해결.
  - 고차원 매핑을 통해 비선형 문제를 선형화하여 해결하면서 커널 함수를 통해 계산량 증가의 문제를 해결하는 방법.

### 커널법과 SVM.
- n차원의 입력 x를 m차원의 특징 데이터 파이(x)로 매핑시킨 후 SVM으로 분류한다고 가정.
- SVM에서의 연산은 개개인의 값 파이(x)가 아니라 두 벡터의 내적 파이(x)*파이(y)를 사용.
- 고차원 매핑 파이(x)를 정의하는 대신에 파이(x)*파이(y)를 하나의 함수 k(x,y)로 정의하여 사용.
  - k(x,y)는 커널 함수.

### 슬랙변수와 커널을 가진 SVM.
- 하이퍼파라미터 c와 커널 함수 k(xy,xj)를 정의해야 함.

































