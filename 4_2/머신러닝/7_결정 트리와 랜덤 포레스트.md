
# 결정 트리와 랜덤 포레스트.

--------------------------------------------------------------------------------------------------------------

> ## 결정 트리.

### 결정 트리 decision tree.
- 주어진 문제에 관해 결정을 내리는 함수를 트리 형태로 구성.
- 뛰어난 설명력 제공.
  - 트리 구조에 각 입력 요소의 역할이 잘 표현되어 학습 결과를 설명.
- 과다적합 문제.
  - 복잡한 함수의 표현 과정에서 데이터의 노이즈에 민감한 문제.
  - 앙상블 학습기법을 결합한 방법 -> 랜덤 포레스트 등장.

### 결정 트리의 예.
- 세탁기 동작 여부(On, Off)를 결정하는 결정 트리.
  - 속성.
    - 판단을 내리는데 사용하는 결정 요인.
    - 날씨, 습도, 세탁량.
  - 리프노드 : 최종 결과.
  - 속성 : 판단을 내리는데 사용하는 결정 요인.

### if문과 결정 트리의 차이.
- if문 : 개발자가 직접 모든 조건을 정의해야 한다.
- 결정 트리 : 데이터를 이용한 학습을 통해 자동으로 생성.

### 학습 과정.
- 결과값이 여러개가 나오는 경우 계속 트리를 분할한다.

### 결정 트리의 학습.
- 각 노드에 어떤 속성(결정 요인)을 배정할 것인가 ?
    - 분할을 적게 하는 방향으로 결정한다.
- 속성 선택을 위한 평가 기준.
  - 지니 불순도 I(N)
    - 각 노드에 할당된 클래스 레이블이 얼마나 다른지 그 혼합 정도를 측정.
  - 지니 평가지수 G(Ra)
    - 속성 a를 갖는 부모 노드 Ra에서 자식 노드들의 지니 불순도의 가중합.

### 정보 이득 information gain.
- 데이터 집합의 분할 전후의 엔트로피의 차이.
- 엔트로피 -> 데이터의 혼잡도, 낮을수록 데이터의 순도가 높음.

### 결정 트리의 문제.
- 과다적합.
  - 모든 학습 데이터에 대해 완벽한 학습.
- 간단한 해결책.
  - 조기종료 early stopping.
    - 데이터를 더 분할해도 성능이 향상되지 않을 때 노드의 분할을 종료.
  - 가지치기 pruning.
    - 전체 트리를 만든 후 불필요한 노드들을 제거.
- 발전된 해결책.
  - 랜덤 포레스트 random forest.

--------------------------------------------------------------------------------------------------------------

> ## 랜덤 포레스트.

### 랜덤 포레스트.
- 결정 트리와 앙상블 학습기법을 결합한 방법.
- 배깅 방법으로 데이터를 리샘플링하여 M개의 결정 트리를 학습하고 결합하는 방법.
    - 결합 방법 -> 주로 보팅법(분류 문제), 출력값의 평균(회귀 문제)
- 용어 정리.
    - 포레스트 : M개의 서로 다른 결정 트리의 집합.
    - 랜덤 : 결정 트리 간의 차이가 랜덤으로 추출된 데이터 샘플에 기인.
- 장점.
  - 간단한 학습기의 결합으로 복잡한 함수 표현 및 일반화 성능 향상.
  - 높은 설명 능력, 빠른 학습.

### 랜덤 포레스트의 학습.
- N개의 데이터로 이루어진 학습 데이터 집합 X를 준비하고, 각 결정 트리의 학습에 사용될 데이터 집합의 크기 ~N을 정한다.
- i번째 결정 트리를 학습하기 위해 트리의 깊이를 결정하고, 학습 데이터 집합 X로부터 ~N개의 데이터를 랜덤하게 선출하여 Xi를 만든다.<br>
  이때 같은 데이터가 중복해서 선출되는 것도 허락한다. (복원추출)
- 데이터 집합 Xi를 이용하여 결정 트리를 학습하여 i번째 판별함수 hi(x)를 얻는다.
- 2~3 과정을 M번 반복하여 서로 다른 M개의 결정 트리를 생성하고, 이들을 결합하여 최종 판별함수(또는 회귀함수) f(h1,...hM)을 찾는다.






















