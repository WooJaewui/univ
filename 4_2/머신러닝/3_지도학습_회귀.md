
# 지도학습 회귀.

--------------------------------------------------------------------------------------------------------------

> ## 회귀의 개념.

### 회귀.
- 입력변수와 출력변수 사이의 매핑 관계를 찾는 것.
- ex) 시계열 예측 -> 주가 예측, 환율 예측 등.

### 회귀 시스템.
    // 입력,출력의 관계.
    D = {(xi, yi)} i=1...N
- xi는 입력값, yi는 예상되는 출력값. (지도학습)
- 학습(데이터 분석)
- 학습 결과 -> 회귀 함수.

### 분류와 회귀의 차이점.
- 분류 : 출력값이 lable이다. (리스트)
- 회귀 : 출력값이 실수이다.

### 학습 목표.
- 예측 오차를 최소화하는 최적의 회귀함수 y = f(x;세타)를 찾는 것.
- 예측 오차를 줄이는 것이 학습의 목표이다.

### 보간법과 회귀.
- 데이터를 가장 잘 표현하는 직선/곡선을 찾는 경우.
- 보간 곡선 -> 제곱 오차가 0이지만 매우 복잡.
- 회귀 직선 -> 작은 오차, 전체적인 데이터의 경향을 보여주는 입출력의 관계 표현에 적합.

### 회귀의 가정.
- 입력값은 약간의 오차(노이즈)를 포함하고 있다라고 가정한다.
- 그래서 회귀 직선을 사용하는 것이 유리할 수 있다.

--------------------------------------------------------------------------------------------------------------

> ## 선형회귀.

### 선형회귀.
    D = {(x1,y1)} i=1,...,N 에 대해,
    (x,y) 관계를 설명할 수 있는 선형 함수 y = w1x + w0 + e를 찾는 것.
- w1 -> 기울기.
- w0 -> 절편.
- e -> 오차 또는 잔차.

### 좋은 선형회귀 모델.
- 모든 데이터에 대해서 잔차가 가능한 작아야 함.
- ei = yi - (wixi + w0)
- 평가 기준.
  - 모든 데이터의 잔차의 합. (부적합한 방법 - 음수/양수 직선이 2개 생김)
  - 잔차의 제곱의 합. (올바른 방법)
    - 주어진 데이터 집합에 대해 유일한 직선을 생성.

### 선형 회귀의 한계.
- x와 y의 관계를 선형 매핑으로 표현할 수 없는 경우.
- 선형화 linearization 과정을 거친 후 선형회귀 적용.
  - x와 y를 ~x와 ~y로 적절히 변형한 후 선형 매핑 관게 ~y = m~x + b를 찾는 방식.
  
### 다른 접근법.
- 보다 복잡한 형태의 곡선으로의 매핑을 위한 방법.

-------------------------------------------------------------------------------------------------------------- 

> ## 로지스틱 회귀.

### 로지스틱 회귀.
- 범주형 데이터의 회귀 logistic regression.
  - 선형회귀분석의 종속변수(출력)을 범주형으로 확장한 것.
  - 분류 문제에 적용 가능.
  - 입력값이 각 클래스에 속하는 확률값을 회귀분석으로 예측.
  - 직선으로 출력 레이블을 표현하기 어렵기 때문에 S자 형태의 로지스틱 회귀 그래프로 표현한다.

### 로지스틱 함수.
- 입력이 (-무한대, 무한대)일 때 항상 (0,1) 범위로 매핑ㅎ하는 S자형 함수. 

### 로지스틱 함수를 이용한 분류.
- 함수의 출력값.
  - 클래스 레이블에 대한 사후확률 P(y= 1|x)
  - P(y = 1|x) <= 0.5 -> x는 c1에 포함.
  - P(y = 1|x) > 0.5 -> x는 c2에 포함.
  
### 오즈비 odds ratio.
- odds = c2에 속할확률/(1-c1에 속할확률)
- 0 <= odds < 무한대.
- odds가 1보다 크면 c2에 속하고, 1보다 작으면 c1에 속한다.

### 로짓 함수 logit function.
- 오즈비에 대한 로그를 취한 것.
- log(c2에 속할확률/(1-c1에 속할확률)) = mx + b
- 로짓함수가 0보다 크면 c2에 속하고, 0보다 작으면 c1에 속한다.

### 로지스틱 회귀의 결정경계.
- mx + b = 0.
- m과 b를 추론(추정)해야 한다.











