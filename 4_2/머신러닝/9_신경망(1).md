
# 신경망(1)

---------------------------------------------------------------------------------------------------------------

> ## 신경망 개요.

### 인공지능 접근 방법.
- SYMBOLIC AI.
  - 부울 논리.
  - 규칙 기반 지식 표현.
  - PROLOG(Language for AI)
  - IBM Deep Blue, Chess AI.
  - 문제 처리과정을 잘 아는 경우에만 적용 가능. (사람이 직접 작성)
- CONNECTIONIST AI.
  - Artificial Neural Networks.
  - 뇌에서 영감을 받은 계산 모형.
  - 신경망 : 퍼셉트론.
  - 딥러닝.
  - 명시적으로 처리과정을 적을 수 없는 경우 사용. 

### 신경망 neural networks. (신경회로망, 인공신경망)
- 생물학적 신경회로망을 모델링한 수학적 함수.
- 원하는 입출력 매핑 함수의 형태를 스스로 찾는 학습 능력을 가짐.
- 데이터를 이용하여 학습이 수행되므로 데이터 분석 툴로 사용.
- 학습 방식(데이터 분석 용도)에 따라 다양한 모델이 존재.

### 심층 신경망 deep networks.
- 가장 발전된 형태의 신경망 모델들.

### 딥 러닝 deep learning.
- 심층 신경망을 이용하여 데이터를 분석하는 머신러닝 기술.

### 신경망의 정의.
- 인간 뇌의 구조와 뇌에서 수행되는 정보처리 방식을 모방함으로써 인간이 처리하는 복잡한 정보처리 능력을 기계를 통해 실현하고자 하는 연구.
- 신경세포 -> 100억 개 이상.
- 세포간 연결 -> 60조 이상.
- 출생 직후에는 신경세포의 연결이 엉성하게 되어 있다.
  - 자라면서 학습을 통해 신경망이 연결된다. (적응성, 학습)

### 생물학적 신경망 - 신경세포 neuron의 구조와 연결.
- 수상돌기 dendrite : 나무 모양으로 가지를 뻗음. (입력을 받아들임)
- 세포체 cell body. (수상돌기의 입력들을 받아들이고 세포핵으로 보냄)
- 세포핵 nucleus. (입력에 대한 연산을 수행함)
- 축색 axon. (세포핵에 의해 연산된 데이터를 출력)
- 시냅스 synapse : 세포와 세포가 연결되는 부분. (축색의 출력을 새로운 세포의 수상돌기가 입력으로 받는 부분)
  - 가중치 : 연결 강도. (흥분성 연결 + 연결, 억제성 연결 - 연결)

### 생물학적 신경망 - 망막의 신경세포들의 계층 구조.
- 계층적으로 되어 있음 (계층 연결, 층상 연결.)

### 인공 신경망 artificial neural networks.
- 인간 뇌의 정보처리 방식을 모델링하는 방법.
  - 신경세포.
  - 신경망의 구조.
  - 학습 메커니즘.

### 인공신경망의 구성 요소.
- 신경세포 neuron, node, unit.
  - 하나의 신경세포가 수행하는 기능을 수학적 함수로 정의.
- 신경망 구조 network structure.
  - 신경세포들이 서로 정보를 전달하는 연결 구조.
- 학습 알고리즘 learning algorithm.
  - 신경망이 원하는 기능을 수행할 수 있도록 신경세포들 간의 연결 강도를 조정하는 방법.
  
### 인공 신경 세포.
    u = ∑ wixi (i=1,...,n)
- 활성화 함수.
  - 뉴런의 핵심 -> 하나의 뉴런의 특성을 결정하는 역할.
  - 시그모이드 함수.
  - 하이퍼탄젠트 함수.
  - ReLU 함수. (최근에 많이 사용)

### 연결 구조.
- 신경세포들의 대표적 연결 방식.
  - 다층 전방향 신경망 multi-layer feed forward neural network.
    - 입력층 input layer.
    - 은닉층 hidden layer.
    - 출력층 output layer.
    - 층상 구조.
    - 정보의 흐름 -> 한쪽 방향(입력층 -> 출력층)
    - Fully connected network, dense network. (이웃한 층 간에 모두 연결이 됨)

### 연결 구조 - 정보 흐름의 방향.
- 전방향 feed-forward 신경망.
- 회귀 recurrent 신경망 (RNN)

### 연결 구조 - 은닉층의 존재 여부.
- 단층 single layer 신경망. (실제 계산을 출력층에서 함)
- 다층 multilayer 신경망 -> 심층 신경망.

### 학습 - 인간 뇌의 학습.
- 성장하면서 뇌 세포들 간의 연결이 형성되어 여러가지 기능을 수행하게 되는 과정.
- 세포들 간의 연결 형성 규칙.
  - 연결된 두 신경세포가 동시에 활성화되면 연결 강도는 강해짐.
  - Hebbian Learning Rule.

### 학습 - 인공신경망의 학습.
- 신경망이 원하는 기능을 수행할 수 있도록 만드는 것.
- 신경망에 어떤 입력 x가 주어졌을 때, 최종적으로 내는 출력 y가 원하는 값이 되도록 가중치 w를 조정하는 것.
- 가중치 조정식.
  - w(t+1) = w(t) + △w(t)
- 가중치 변화량을 결정하는 방법.
  - 학습 데이터 사용.
- 반복적인 가중치 수정을 통해 점점 원하는 기능에 근접해 감.

### 학습의 종류.
- 지도학습 supervised learning.
  - 입력값 x에 대한 목표 출력값 t이 함께 주어짐.
  - 주어진 입력 x에 대한 신경망의 출력값 y가 원하는 목표값 t에 가까워지도록 가중치 w를 수정.
  - 오류 역전파 학습 알고리즘.
- 비지도학습 unsupervised learning.
  - 입력값 x만 주어짐.
  - 비슷한 입력에 대해 비슷한 출력을 내도록 학습.
  - self-organizing feature map, Boltzmann machine.
- 강화학습 reinforcement learning.
  - 입력 x에 대한 신경망의 출력값 y의 보상이 최대가 되도록 가중치를 수정. (15강)

### 응용 관점에서의 신경망에 대한 이해.
- 하나의 함수로 취급.
  - 기능 : 입력 x를 받아 출력 y를 계산.
  - 수학적 정의 : y = f(x)
- 함수 f를 결정하는 요소.
  - 신경세포의 활성화 함수와 연결 구조 -> 고정된 형태.
  - 연결 가중치 -> 학습을 통해 함수 f의 형태를 조정.
    - 신경망의 학습 -> 원하는 함수 f를 찾는 과정.

### 신경망의 특징.
- 표현 representation 능력.
  - 신경망은 어떤 형태의 함수도 표현할 수 있음.
- 학습 learning 능력.
  - 데이터에 대한 학습을 통해 최적의 함수를 찾을 수 있음.
- 일반화 generalization 능력.
  - 데이터에 대한 단순한 암기가 아닌 데이터에서 일반화된 규칙을 찾음.
  - 새로운 데이터에 대해서도 처리 가능.

---------------------------------------------------------------------------------------------------------------

> ## 다층 퍼셉트론.

### M-P 뉴런.
- 1943.MaCulloch & Piits.
- 단일 신경세포에 대한 첫 번째 모델.

### 퍼셉트론 Perceptron.
- 1958.Rosenblatt.
- M-P 뉴런을 여러 개 결합하여 네트워크 형태를 갖춘 신경망.
- 패턴인식을 수행하는 최초의 신경망 -> 단층 전방향 신경망.
- 뉴런.
  - M-P 뉴런 -> 계단함수.
- 연결 구조.
  - 단층, 전방향, 완전 연결 fully-connected.
- 학습 규칙.
  - 이진 입출력을 사용한 지도학습.

### 퍼셉트론의 한계.
- 선형 판별함수.
  - 비선형 결정경계를 표현할 수 없음.
- XOR 문제.
  - Minsky & Papert -> XOR 문제의 해결 불가능을 지적.
  - 퍼셉트론은 직선으로 표현되는대, XOR 문제는 직선으로 나눌 수 없다. (층을 추가해야만 계산 가능)

### 다층 퍼셉트론.
- MLP, Multi-Layer Perceptron.
  - 1개 이상의 은닉층을 가짐. (대부분 1개만 가짐)
- 뉴런.
  - 출력은 입력에 대한 비선형 매핑.
  - 입력은 시그모이드 함수, 하이퍼탄젠트 함수.
  - 출력에서는 다른 함수 사용 가능.
- 연결 구조.
  - 다층, 전방향, 완전연결.
- 학습 알고리즘.
  - 오류 역전파 error backpropagation 알고리즘 -> 지도학습.

### 다층 퍼셉트론의 표현 능력.
- 가중치에 변화에 따라 표현할 수 있는 값이 매우 다양하다.
- 입력 1개 - 출력 1개.
  - 하나의 은닉층을 가진 MLP는 임의의 정확도로 모든 연속 함수의 근사가 가능.


























