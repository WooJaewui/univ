# 머신러닝 소개.

----------------------------------------------------------------------------------------------------

> ## 머신러닝의 개념.

### 인공지능, 머신러닝, 딥러닝 관계.
- 인공지능 > 머신러닝 > 딥러닝.

### 인공지능이란 ?
- 인공지능 AI Artificial Intelligence.
    - 인간 지능을 모방하여 문제해결을 위해 사람처럼 학습/이해하는 기계를 만듦.
    - 약 인공지능 weak AI.
      - 실제 지능의 소유 여부와 상관없이 지능적인 것처럼 행동하는 기계.
      - 단지 정의된 특정 목적을 달성하고 문제를 해결하는 능력.
      - 행동의 결과만 중요.
    - 강 인공지능 strong AI.
      - 지능의 모방이 아닌 실제로 인간처럼 생각하는 기계.
      - 스스로 문제 정의 및 해결, 지속적인 학습, 자아, 감정 등의 광범위한 지적 능력을 포함.
      - AGI Artificial General Intelligence, Human-Level AI.

### 머신러닝이란 ?
- 기계학습.
- 인간이 갖고 있는 고유의 지능적 기능인 학습 능력을 기계를 통해 구현하기 위한 접근 방법.
- 주어진 데이터를 분석하여 그로부터 일반적인 규칙이나 새로운 지식을 기계 스스로가 자동으로 추출하기 위한 접근 방법.

### 머신러닝 왜 필요한가 ?
- 데이터의 다양한 변형을 다루기 위해서.

### 딥러닝.
- 심층 학습 deep learning.
    - 심층 신경망 기반의 머신러닝 분야.
    - 신경망에 대해 잘 알아야 활용할 수 있다.
    - 신경망.
      - 입력층 -> 은닉층 -> 출력층으로 구성되어 있다.
      - 자세한 내용은 이후에 배운다.

----------------------------------------------------------------------------------------------------

> ## 머신러닝의 처리 과정.

### 머신러닝의 처리 과정.
- 학습 단계.
    - 학습 데이터 집합.
    - 학습 데이터 전처리 : 분석에 용이하도록 데이터를 가공/분석.
    - 특징 추출 : 전처리한 데이터에서 필요한 데이터 특징을 추출. (불필요한 데이터 없애기)
    - 학습(데이터 분석) : 특징 추출을 통해 얻은 데이터를 분석.  
    - 결정함수 : 원하는 입력과 원하는 출력의 관계를 매핑.
- 추론 단계.
    - 분류, 회귀, 군집화 : 머신러닝에서 다루는 주제 영역. 
    - 판단 결과 : 최종 결과물.

### 머신러닝 시스템 개발 과정.
- 문제파악 -> 데이터 수집 및 이해 -> 데이터 준비(전처리), 특징 추출 -> 모델 수립 및 분석 -> 모델 평가 -> 배포.
- 모델 평가에서 오류를 발견하면 문제파악부터 다시 시작한다.

----------------------------------------------------------------------------------------------------

> ## 머신러닝의 기본 요소.

### 데이터와 데이터 분포.
- 데이터 표현.
  - n차원의 벡터.
- flatten.
  - n차원의 데이터를 1차원으로 만든다.

### 데이터 집합의 분포 특성.
- 해당 공간상에서 점들이 분포된 모양.
- 2차원 데이터 집합의 산점도 scatter plot.

### 특징추출.
- 주어진 데이터를 처리하는 데 핵심이 되는 정보를 추출하는 것.
  - 목적 : 비용(계산량, 메모리) 절약, 데이터에 포함된 불필요한 정보의 제거.
- 사영(projection)에 의한 특징 추출.
  - 교재 7장 특징 추출에서 자세히 배움.

### 성능 평가.
- 학습 시스템.
  - 데이터로부터 학습을 통해 추출하고자 하는 정보를 표현하는 시스템.
  - 입력 x -> 학습 시스템 f -> 출력 y.
  - 입/출력 매핑 형태의 함수로 정의.
  - 학습 -> 데이터를 이용하여 함수 f를 찾는 것 -> 학습 시스템의 매개변수를 찾는 것.
  - 학습의 궁극적 목표는 앞으로 주어질 데이터에 대한 성능을 최대화하는 것.
- 목적함수 objective function.
  - 주어진 데이터 집합을 이용하여 학습 시스템이 달성해야 하는 목표를 기계가 알 수 있는 수학적 함수로 정의한 것.
- 오차함수 error function.
  - 대표적인 목적함수.
  - 학습 시스템의 출력값과 원하는 출력값의 차이로 정의.
  - 학습의 목적 -> 오차를 최소화하는 것.

### 오차함수를 이용한 성능 평가 기준.
- 학습 오차 training error.
  - 학습에 사용된 데이터(학습 데이터) 집합에 대해 계산된 오차.
- 테스트 오차 test error. (경험 오차 empirical error)
  - 학습에 사용되지 않은 새로운 데이터(테스트 데이터) 집합에 대해 계산된 오차.
- 일반화 오차 generalization error.
  - 관찰될 수 있는 모든 데이터 분포 전체에 대해 정의되는 오차.
  - 실제 계산이 불가해서 테스트 오차로 대신하여 평가.

### 일반화 오차의 추정.
- 교차검증법 cross validation method.
  - 제한된 데이터 집합을 이용하여 일반화 오차에 좀 더 근접한 오차값을 얻어 내기 위한 방법.
  - K-분절 교차검증법.

----------------------------------------------------------------------------------------------------

> ## 머신러닝에서의 주제.

### 머신러닝에서의 주제.
- 데이터 분석.
  - 분류 classification.
  - 회귀 regression.
  - 군집화 clustering.
- 데이터 표현.
  - 특징추출 feature extraction.

### 분류 classification.
- 입력 데이터가 어떤 부류에 속하는지를 자동으로 판단하는 문제.
- 예 : ~인식 -> 숫자인식, 얼굴인식, 생체인식 등.
- 출력 값이 일정 범위의 값을 가진다. (0~9)
- 학습 목표.
  - 분류 오차를 최소화하는 최적의 결정경계를 찾아야 한다.
- 성능 평가 척도.
  - 분류율(%) = (분류 성공 데이터 개수 / 전체 데이터 개수) x 100.
  - 분류오차(%) = (분류 실패 데이터 개수 / 전체 데이터 개수) x 100. 
- 결정 경계.
  - 판별함수/결정함수 : g(x)
  - g(x) = g(x1, x2) = x2 - x1 = 0.
  - 직선 또는 곡선으로 표현하게 됨.

### 회귀 regression.
- 입력변수와 출력변수 사이의 매핑 관계를 분석.
- 예 : 시간에 따른 데이터의 변화를 분석. (시계열 예측)
- 출력 값이 연속된 값을 가진다. (그래프)
- 학습 목표.
  - 회귀 오차를 최소화하는 최적의 회귀함수를 찾는 것.
  - 제곱 오차 squared error를 사용한다.
    
### 군집화 clustering.
- 데이터 집합을 서로 비슷한 몇 개의 그룹으로 묶는 문제.
- 분류 문제와 달리 클래스 정보가 주어지지 않음.
- 예 : 데이터 그룹화, 영상 분할.
- K-평균 군집화, 계층적 군집화, 가우시안 혼합 모델, 신경망.
- 학습 목표.
  - 최적의 클러스터의 집합을 찾는 것.
  - 클러스터 내의 분산은 최소화, 클러스터 간의 분산은 최대화.

### 특징추출 feature extraction.
- 원래 데이터로부터 데이터 분석에 적용하기 좋은 특징을 찾아내는 문제.
- 예 : 영상 데이터의 차원 축소, 데이터 시각화.
- 주성분분석 PCA, 선형판별분석 LDA, MDS, t-SNE.
- 학습 목표.
  - 분석 목적에 따라 달라짐.
  - 예 : 차원 축소 -> 원래 데이터가 가지는 정보로부터의 손실량 최소화.

----------------------------------------------------------------------------------------------------

> ## 학습 시스템 관련 개념.

### 머신러닝의 유형.
- 지도학습(교사학습) supervised learning.
  - 학습할 때 시스템이 출력해야 할 목표 출력값(교사)을 함께 제공.
  - 분류, 회귀.
- 비지도학습(비교사학습) unsupervised learning.
  - 학습할 때 목표 출력값에 대한 정보가 없음.
  - 군집화.
- 준지도학습(반지도학습) semi-supervised learning.
  - 지도학습+비지도학습 -> 클래스 레이블링 비용을 줄이려는 목적.
- 강화학습 reinforcement learning.
  - 출력값에 대한 교사 신호가 보상(reward) 형태로 제공.
  - 교사 신호는 정확한 값이 아니고, 즉시 주어지지 않음.

### 과다적합 overfitting.
- 학습 시스템이 학습 데이터에 대해서만 지나치게 적합한 형태로 결정경계가 형성되는 현상.
  - 원인 : 학습 데이터의 확률적 잡음과 학습 데이터 개수의 부족.
  - 영향 : 일반화 성능 저하 초래.
  - 학습 시스템의 복잡도를 조정하는 방법.
    - 다양한 변형을 가진 충분한 학습 데이터 사용.
    - 조기 종료 방법.
    - 정규항을 가진 오차함수 사용.
    - 모델 선택 방법.

### 앙상블 학습 ensemble learning.
- 복수 개의 간단한 학습 시스템을 결합하여 일반화 성능을 향상시킴.

### 능동학습 active learning. 
- 학습 과정에서 데이터를 선별적으로 선택하여 수행.

### 메타 학습과 자동 머신러닝 meta-learning, auto ML.
- 학습 시스템의 복잡도 등의 하이퍼파라미터까지 학습을 통해 최적화.

### 지속/증분 학습 continual/incremental learning.
- 기존에 학습된 내용에 대한 손실 없이 새로운 내용을 추가로 학습.








